{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from rdquantum.hamiltonian import Rydberg_Cz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hamiltonian\n",
    "H = Rydberg_Cz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = gym.make('rdquantum/HamiltonianTrainer-v2023.04.22', Hamiltonian=Rydberg_Cz)\n",
    "observation, info = env.reset()\n",
    "# print(observation, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "algo = 'REINFORCE'\n",
    "B = 30 # batch_size\n",
    "EPOCHS = 50\n",
    "eval_interval = 1\n",
    "lr = 1e-2 # 1e-2 for SGD\n",
    "policy_steps = 20\n",
    "\n",
    "log_prob_clip = 5\n",
    "grad_clip = 0.001\n",
    "importance_ratio_eps = 0.2\n",
    "value_loss_coeff = 0.5\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rootdir = r'.'\n",
    "r_amp = H.r_amp\n",
    "r_gate_time = H.r_gate_time\n",
    "# print(r_amp, r_gate_time)\n",
    "\n",
    "\n",
    "# trainable variables\n",
    "actions = ['omega_p_amp', 'omega_r_amp', 'delta_p_amp', 'gate_time']\n",
    "mean = {s : tf.Variable(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32), name='mean_'+s) for s in actions}\n",
    "sigma = {s : tf.Variable(0.5, name='sigma_'+s) for s in actions}\n",
    "baseline = tf.Variable(0.0, name='baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_action = {\n",
    "    'omega_p_amp': [100/H.r_amp],\n",
    "    'omega_r_amp': [175/H.r_amp],\n",
    "    'delta_p_amp': [400/H.r_amp],\n",
    "    'gate_time': [1.0/H.r_gate_time]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_sampler(a, _type):\n",
    "    # print('a: ', a, '\\n')\n",
    "    rewards = []\n",
    "    \n",
    "    for i in range(B):\n",
    "        a_np = {s : np.array(a[s][i] if _type=='collection' else [a[s]]) for s in actions}\n",
    "        # print('a_np: ', a_np, '\\n')\n",
    "        observation, reward, terminated, truncated, info = env.step(a_np)\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return tf.cast(rewards, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_prob(a, mean, sigma):\n",
    "    sigma_eps = 1e-5 # for mumerical stability\n",
    "    log_prob = 0.\n",
    "    for s in a.keys():\n",
    "        log_prob += - tf.math.log(tf.math.abs(sigma[s]) + sigma_eps) \\\n",
    "            - 0.5 * (a[s] - mean[s])**2 / (sigma[s]**2 + sigma_eps)\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_sampler(actions, sample_batch = 1):\n",
    "    N = {s : tfp.distributions.TruncatedNormal(loc=mean[s], scale=sigma[s], low=0, high=1) for s in actions}\n",
    "    a = {s : N[s].sample(B) for s in actions}\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  tf.Tensor(\n",
      "[-1.  1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.\n",
      " -1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 2:  tf.Tensor(\n",
      "[ 1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1.\n",
      " -1.  1.  1.  1.  1. -1. -1.  1.  1.  1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 3:  tf.Tensor(\n",
      "[-1.  1. -1.  1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1.\n",
      "  1. -1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 4:  tf.Tensor(\n",
      "[ 1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1.  1.  1. -1.\n",
      " -1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 5:  tf.Tensor(\n",
      "[ 1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1.\n",
      "  1.  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 6:  tf.Tensor(\n",
      "[-1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.\n",
      "  1.  1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 7:  tf.Tensor(\n",
      "[-1.  1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1.\n",
      " -1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 8:  tf.Tensor(\n",
      "[-1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.\n",
      "  1.  1. -1.  1. -1.  1.  1.  1. -1.  1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 9:  tf.Tensor(\n",
      "[-1. -1. -1.  1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1.\n",
      "  1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 10:  tf.Tensor(\n",
      "[-1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1.\n",
      " -1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 11:  tf.Tensor(\n",
      "[-1.  1.  1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1. -1.  1.  1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 12:  tf.Tensor(\n",
      "[ 1. -1. -1. -1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1.\n",
      "  1. -1. -1.  1. -1.  1.  1.  1.  1. -1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 13:  tf.Tensor(\n",
      "[ 1. -1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.\n",
      " -1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 14:  tf.Tensor(\n",
      "[ 1.  1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.\n",
      "  1.  1. -1.  1. -1. -1.  1.  1.  1. -1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 15:  tf.Tensor(\n",
      "[ 1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 16:  tf.Tensor(\n",
      "[ 1. -1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1. -1. -1. -1. -1.\n",
      "  1.  1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 17:  tf.Tensor(\n",
      "[ 1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1.  1.\n",
      "  1.  1.  1.  1. -1. -1.  1.  1.  1.  1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 18:  tf.Tensor(\n",
      "[ 1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.\n",
      " -1.  1. -1.  1.  1.  1. -1. -1.  1. -1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 19:  tf.Tensor(\n",
      "[ 1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.\n",
      "  1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 20:  tf.Tensor(\n",
      "[-1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1.  1.  1.\n",
      " -1. -1.  1. -1.  1.  1. -1. -1.  1. -1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 21:  tf.Tensor(\n",
      "[-1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1.\n",
      "  1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 22:  tf.Tensor(\n",
      "[ 1. -1.  1.  1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1. -1.  1.\n",
      "  1. -1.  1. -1.  1.  1. -1.  1.  1.  1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 23:  tf.Tensor(\n",
      "[ 1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1. -1.\n",
      "  1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 24:  tf.Tensor(\n",
      "[-1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.\n",
      " -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 25:  tf.Tensor(\n",
      "[ 1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1.\n",
      " -1.  1.  1. -1.  1. -1. -1. -1. -1.  1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 26:  tf.Tensor(\n",
      "[-1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1.\n",
      "  1.  1.  1.  1. -1.  1.  1. -1.  1. -1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 27:  tf.Tensor(\n",
      "[ 1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1.  1. -1. -1. -1. -1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 28:  tf.Tensor(\n",
      "[ 1.  1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1. -1.  1.  1.\n",
      " -1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 29:  tf.Tensor(\n",
      "[-1.  1.  1. -1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1.  1.  1. -1.  1.\n",
      "  1. -1.  1.  1.  1.  1.  1.  1.  1. -1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 30:  tf.Tensor(\n",
      "[ 1. -1.  1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 31:  tf.Tensor(\n",
      "[-1. -1. -1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1.\n",
      "  1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 32:  tf.Tensor(\n",
      "[ 1.  1. -1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1. -1. -1.  1.  1. -1.  1.  1. -1. -1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 33:  tf.Tensor(\n",
      "[-1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.\n",
      " -1. -1. -1.  1.  1.  1. -1.  1. -1.  1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 34:  tf.Tensor(\n",
      "[ 1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1. -1.\n",
      "  1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 35:  tf.Tensor(\n",
      "[ 1.  1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1. -1.  1. -1.\n",
      " -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 36:  tf.Tensor(\n",
      "[ 1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1. -1.\n",
      " -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 37:  tf.Tensor(\n",
      "[ 1. -1.  1.  1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1.\n",
      " -1.  1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 38:  tf.Tensor(\n",
      "[-1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1. -1.\n",
      " -1.  1.  1. -1.  1. -1.  1.  1.  1.  1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 39:  tf.Tensor(\n",
      "[-1. -1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1.\n",
      "  1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 40:  tf.Tensor(\n",
      "[ 1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1.  1.\n",
      " -1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 41:  tf.Tensor(\n",
      "[-1.  1. -1. -1.  1.  1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.\n",
      " -1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 42:  tf.Tensor(\n",
      "[ 1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 43:  tf.Tensor(\n",
      "[ 1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1. -1.\n",
      "  1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 44:  tf.Tensor(\n",
      "[-1. -1. -1.  1. -1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1.  1. -1.  1.  1.  1. -1. -1. -1.  1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 45:  tf.Tensor(\n",
      "[ 1.  1.  1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1. -1. -1.  1. -1.\n",
      "  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 46:  tf.Tensor(\n",
      "[ 1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      " -1.  1.  1.  1.  1.  1. -1. -1.  1. -1. -1. -1.], shape=(30,), dtype=float32)\n",
      "Epoch 47:  tf.Tensor(\n",
      "[ 1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1.\n",
      "  1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 48:  tf.Tensor(\n",
      "[ 1.  1.  1. -1.  1.  1.  1.  1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 49:  tf.Tensor(\n",
      "[ 1. -1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1.\n",
      " -1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.], shape=(30,), dtype=float32)\n",
      "Epoch 50:  tf.Tensor(\n",
      "[-1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1. -1.  1.\n",
      " -1. -1.  1.  1. -1. -1.  1. -1. -1. -1.  1. -1.], shape=(30,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_samples = 0\n",
    "train_rewards = []\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "\n",
    "    train_samples += B\n",
    "    # print('train_samples:', train_samples)\n",
    "\n",
    "    # sample a batch of actions from Gaussian policy\n",
    "    a = action_sampler(actions, sample_batch=B)\n",
    "\n",
    "    # collect those rewards\n",
    "    R =  reward_sampler(a, 'collection')\n",
    "    # print('rewards: ', R)\n",
    "\n",
    "    # log prob according to old policy (required for importance ratio)\n",
    "    if epoch == 1: mean_old, sigma_old = mean, sigma\n",
    "    log_prob_old = compute_log_prob(a, mean_old, sigma_old)\n",
    "    log_prob_old = tf.clip_by_value(log_prob_old, -log_prob_clip, log_prob_clip)\n",
    "    mean_old = tf.nest.map_structure(tf.identity, mean)\n",
    "    sigma_old = tf.nest.map_structure(tf.identity, sigma)\n",
    "    \n",
    "    # calculate policy loss and do several gradient updates\n",
    "    for i in range(policy_steps):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # log prob according to the current policy\n",
    "            log_prob = compute_log_prob(a, mean, sigma)\n",
    "            log_prob = tf.clip_by_value(log_prob, -log_prob_clip, log_prob_clip)\n",
    "\n",
    "            A = R - baseline # action advantages\n",
    "\n",
    "            if algo == 'REINFORCE':\n",
    "                policy_loss_batch = - A * log_prob\n",
    "\n",
    "            if algo == 'PPO':\n",
    "                importance_ratio = tf.math.exp(log_prob - log_prob_old)\n",
    "                importance_ratio_clip = tf.clip_by_value(importance_ratio, \n",
    "                            1-importance_ratio_eps, 1+importance_ratio_eps)\n",
    "                policy_loss_batch = -tf.minimum(importance_ratio*A, importance_ratio_clip*A)\n",
    "\n",
    "            policy_loss = tf.reduce_mean(policy_loss_batch) # reduce over batch\n",
    "            value_loss = tf.reduce_mean(A**2)\n",
    "            loss = policy_loss + value_loss_coeff * value_loss\n",
    "            # print(loss)\n",
    "\n",
    "            grads = tape.gradient(loss, tape.watched_variables())\n",
    "            grads = tf.clip_by_value(grads, -grad_clip, grad_clip)\n",
    "            optimizer.apply_gradients(zip(grads, tape.watched_variables()))\n",
    "            \n",
    "    print('Epoch %d: ' %(epoch), R)\n",
    "    train_rewards.append(np.array(R))\n",
    "    # log['train_actions'].append(np.array(a['theta']))\n",
    "    # log['train_epochs'].append(epoch)\n",
    "    # log['train_samples'].append(train_samples)\n",
    "    # if epoch % eval_interval == 0: evaluation(epoch, log)\n",
    "\n",
    "run_params = dict(B = B, EPOCHS = EPOCHS, eval_interval = eval_interval,\n",
    "        lr = lr, policy_steps = policy_steps, log_prob_clip = log_prob_clip,\n",
    "        grad_clip = grad_clip, importance_ratio_eps = importance_ratio_eps,\n",
    "        value_loss_coeff = value_loss_coeff)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(30,), dtype=float32, numpy=\n",
       "array([-1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,\n",
       "       -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "       -1., -1.,  1., -1.], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 1707,
     "status": "ok",
     "timestamp": 1681368543198,
     "user": {
      "displayName": "張子軒",
      "userId": "11622394988518650577"
     },
     "user_tz": -480
    },
    "id": "IXTctuZi0YqU",
    "outputId": "6de62e4a-2c7a-49b5-e637-367e0a0aa43b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x345.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = np.array(train_rewards)\n",
    "plt.matshow(np.reshape(result, (EPOCHS, B)).transpose())\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Episode\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().tick_params(axis=\"x\", bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEn6t9e6XqHq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMePkOqbTVxOTgKwEfY0Fg1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
